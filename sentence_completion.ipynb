{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2xpsn1oJkd-"
      },
      "source": [
        "# Sentence Completion with RNN/LSTM\n",
        "\n",
        "This notebook builds a simple next-word prediction model using quote data. We use:\n",
        "- **Preprocessing**: lowercasing and removing punctuation\n",
        "- **Tokenization**: Keras Tokenizer to convert text to sequences\n",
        "- **Vectorization**: Padding sequences + one-hot encoding labels with **sklearn**\n",
        "- **Models**: SimpleRNN and LSTM (Keras)\n",
        "\n",
        "Run all cells in order. Upload `qoute_dataset.csv` in Colab (or mount Drive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8khFRwLaJkd_"
      },
      "source": [
        "## 1. Imports and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QlOY-pX4Jkd_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VaW_FjQFJkeA",
        "outputId": "f97bcba7-92f6-402f-8435-9ece4e15f8dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3038,\n  \"fields\": [\n    {\n      \"column\": \"quote\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3037,\n        \"samples\": [\n          \"Would it save you a lot of time if I just gave up and went mad now?\",\n          \"\\u0627\\u0644\\u0643\\u0631\\u0627\\u0647\\u064a\\u0629 \\u062a\\u0643\\u0644\\u0641 \\u0623\\u0643\\u062b\\u0631 \\u0645\\u0646 \\u0627\\u0644\\u062d\\u0628.. \\u0644\\u0623\\u0646\\u0647\\u0627 \\u0625\\u062d\\u0633\\u0627\\u0633 \\u063a\\u064a\\u0631 \\u0637\\u0628\\u064a\\u0639\\u064a.. \\u0625\\u062d\\u0633\\u0627\\u0633 \\u0639\\u0643\\u0633\\u064a \\u0645\\u062b\\u0644 \\u062d\\u0631\\u0643\\u0629 \\u0627\\u0644\\u0623\\u062c\\u0633\\u0627\\u0645 \\u0636\\u062f \\u062c\\u0627\\u0630\\u0628\\u064a\\u0629 \\u0627\\u0644\\u0623\\u0631\\u0636.. \\u062a\\u062d\\u062a\\u0627\\u062c \\u0625\\u0644\\u0649 \\u0642\\u0648\\u0629 \\u0625\\u0636\\u0627\\u0641\\u064a\\u0629 \\u0648\\u062a\\u0633\\u062a\\u0647\\u0644\\u0643 \\u0648\\u0642\\u0648\\u062f\\u0627\\u064b \\u0623\\u0643\\u062b\\u0631\",\n          \"The only thing worse than a boy who hates you: a boy that loves you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1005,\n        \"samples\": [\n          \"Ashleigh Brilliant\",\n          \"Chuck Klosterman,\",\n          \"Coco Chanel,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2731cc8c-b9d3-4e17-8aa0-99263aac92fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>Author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“The world as we have created it is a process ...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“It is our choices, Harry, that show what we t...</td>\n",
              "      <td>J.K. Rowling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“There are only two ways to live your life. On...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
              "      <td>Jane Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2731cc8c-b9d3-4e17-8aa0-99263aac92fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2731cc8c-b9d3-4e17-8aa0-99263aac92fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2731cc8c-b9d3-4e17-8aa0-99263aac92fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               quote           Author\n",
              "0  “The world as we have created it is a process ...  Albert Einstein\n",
              "1  “It is our choices, Harry, that show what we t...     J.K. Rowling\n",
              "2  “There are only two ways to live your life. On...  Albert Einstein\n",
              "3  “The person, be it gentleman or lady, who has ...      Jane Austen\n",
              "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the quotes dataset (upload qoute_dataset.csv in Colab if needed)\n",
        "df = pd.read_csv('qoute_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "yo5-a1NPJkeA",
        "outputId": "7cfe436e-102e-429f-c251-a0e644870553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of quotes: 3038\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“The world as we have created it is a process ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“It is our choices, Harry, that show what we t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“There are only two ways to live your life. On...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    “The world as we have created it is a process ...\n",
              "1    “It is our choices, Harry, that show what we t...\n",
              "2    “There are only two ways to live your life. On...\n",
              "3    “The person, be it gentleman or lady, who has ...\n",
              "4    “Imperfection is beauty, madness is genius and...\n",
              "Name: quote, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use only the quote column for sentence completion\n",
        "quotes = df['quote']\n",
        "print('Number of quotes:', len(quotes))\n",
        "quotes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kmeMxeQJkeB"
      },
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "Clean text: lowercase and remove punctuation so the model sees consistent tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "trfSBD1ZJkeB"
      },
      "outputs": [],
      "source": [
        "# Convert to lowercase\n",
        "quotes = quotes.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "WV9OR6DBJkeB",
        "outputId": "036bb202-51ab-4d0f-e047-c760c77c8dbe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“the world as we have created it is a process ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“it is our choices harry that show what we tru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“there are only two ways to live your life one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“the person be it gentleman or lady who has no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“imperfection is beauty madness is genius and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    “the world as we have created it is a process ...\n",
              "1    “it is our choices harry that show what we tru...\n",
              "2    “there are only two ways to live your life one...\n",
              "3    “the person be it gentleman or lady who has no...\n",
              "4    “imperfection is beauty madness is genius and ...\n",
              "dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove punctuation using a translation table\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "new_quotes = []\n",
        "for q in quotes:\n",
        "    new_quotes.append(q.translate(translator))\n",
        "quotes = pd.Series(new_quotes)\n",
        "quotes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSHlPR1SJkeB"
      },
      "source": [
        "## 3. Tokenization\n",
        "\n",
        "Convert each quote into a sequence of word indices. We limit vocabulary size to keep the model small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Yc9JQEHjJkeC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Use Keras Tokenizer (reference via tf.keras to avoid import resolution issues)\n",
        "Tokenizer = tf.keras.preprocessing.text.Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1J8QOJQ1JkeC"
      },
      "outputs": [],
      "source": [
        "# Vocabulary size: only keep top 10000 most frequent words\n",
        "vocab_size = 10000\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(quotes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFaCVzxeJkeC",
        "outputId": "490e73f5-6557-4d44-ae37-376bb3867d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique words in word_index: 8978\n",
            "Top 10 words: [('the', 1), ('you', 2), ('to', 3), ('and', 4), ('a', 5), ('i', 6), ('is', 7), ('of', 8), ('that', 9), ('it', 10)]\n"
          ]
        }
      ],
      "source": [
        "# Word index: mapping from word -> integer index\n",
        "word_index = tokenizer.word_index\n",
        "print('Unique words in word_index:', len(word_index))\n",
        "print('Top 10 words:', list(word_index.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG691uj4JkeC",
        "outputId": "f3ada4e9-3d37-429e-cd0c-8d6a1ea050e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example - first quote as sequence: [713, 62, 29, 19, 16, 946, 10, 7, 5, 1156, 8, 70, 293, 10, 145] ...\n"
          ]
        }
      ],
      "source": [
        "# Convert each quote to a list of word indices\n",
        "sequences = tokenizer.texts_to_sequences(quotes)\n",
        "print('Example - first quote as sequence:', sequences[0][:15], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLoWbHM7JkeC"
      },
      "source": [
        "## 4. Creating input (X) and target (Y)\n",
        "\n",
        "For each quote we create training pairs: **input** = words so far, **target** = next word. So we learn to predict the next word given previous words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GUUMFwWIJkeC"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        input_seq = seq[:i]      # words 0 to i-1\n",
        "        next_word = seq[i]       # next word index\n",
        "        X.append(input_seq)\n",
        "        Y.append(next_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzM9h42OJkeD",
        "outputId": "13fcf732-2653-470d-cfe6-cd31d5b652df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sequence length: 746\n"
          ]
        }
      ],
      "source": [
        "# Find maximum sequence length (we need this for padding later)\n",
        "max_length = 0\n",
        "for seq in sequences:\n",
        "    if len(seq) > max_length:\n",
        "        max_length = len(seq)\n",
        "print('Max sequence length:', max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLN3Y2xJkeD"
      },
      "source": [
        "## 5. Padding\n",
        "\n",
        "All input sequences must have the same length. We pad shorter sequences with zeros at the beginning (`padding='pre'`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN0sZBf3JkeD",
        "outputId": "043b5859-f9f1-43e7-e7f1-a70786cac967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_padded shape: (85271, 746)\n"
          ]
        }
      ],
      "source": [
        "pad_sequences = tf.keras.preprocessing.sequence.pad_sequences\n",
        "X_padded = pad_sequences(X, maxlen=max_length, padding='pre')\n",
        "print('X_padded shape:', X_padded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anmiKNf3JkeD"
      },
      "source": [
        "## 6. Vectorization (one-hot encoding with sklearn)\n",
        "\n",
        "Targets are word indices. We one-hot encode them so the model predicts a probability over `vocab_size` classes. We use **sklearn.preprocessing.OneHotEncoder**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SwcLoGtJkeD",
        "outputId": "5e7a3a38-56e8-4f88-9e0d-eac513263af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_encoded shape: (85271, 10000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Turn Y into a numpy array and make it 2D (one column) - sklearn needs 2D input\n",
        "y = np.array(Y)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Tokenizer uses 1,2,3,... for words. One-hot needs 0,1,2,... so we subtract 1\n",
        "y = y - 1\n",
        "y = y.astype(int)\n",
        "\n",
        "# Tell OneHotEncoder we have exactly vocab_size classes (0 to vocab_size-1)\n",
        "# sparse_output=False means we get a normal array (not sparse) for Keras\n",
        "encoder = OneHotEncoder(categories=[list(range(vocab_size))], sparse_output=False)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "print('y_encoded shape:', y_encoded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_bpD5-RJkeD"
      },
      "source": [
        "## 7. Model building\n",
        "\n",
        "We use **Embedding** → **RNN (SimpleRNN or LSTM)** → **Dense(softmax)**. The output is a probability distribution over the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VNmeA7i0JkeE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MEtSwHqdJkeE"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 50\n",
        "rnn_units = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7D_Utu1DJkeE",
        "outputId": "206a91df-31fc-425d-9dcd-bf7080d4e5ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Simple RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "rnn_model.add(SimpleRNN(units=rnn_units))\n",
        "rnn_model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "M8iVAWyqJkeE",
        "outputId": "7039fed0-867e-4a8e-f192-36d5dc42b2fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LSTM model (usually better for longer sequences)\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "lstm_model.add(LSTM(units=rnn_units))\n",
        "lstm_model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ2dn11VJkeE"
      },
      "source": [
        "## 8. Training\n",
        "\n",
        "Train the RNN and LSTM on the padded inputs and one-hot targets. We use a fraction of data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MIn_byVJkeE",
        "outputId": "7248e1dc-aa1d-4d7b-e116-8a56be20397c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 70ms/step - accuracy: 0.0309 - loss: 7.4237 - val_accuracy: 0.0371 - val_loss: 6.8304\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.0389 - loss: 6.5658 - val_accuracy: 0.0446 - val_loss: 6.8694\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.0500 - loss: 6.4091 - val_accuracy: 0.0517 - val_loss: 6.8268\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.0611 - loss: 6.2169 - val_accuracy: 0.0725 - val_loss: 6.6972\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.0791 - loss: 6.2042 - val_accuracy: 0.0874 - val_loss: 6.5122\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.0837 - loss: 6.3247 - val_accuracy: 0.0884 - val_loss: 6.5105\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.1020 - loss: 5.8697 - val_accuracy: 0.0950 - val_loss: 6.4899\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.1121 - loss: 5.7049 - val_accuracy: 0.0978 - val_loss: 6.5027\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.1178 - loss: 5.5908 - val_accuracy: 0.1001 - val_loss: 6.3956\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 63ms/step - accuracy: 0.1249 - loss: 5.4563 - val_accuracy: 0.1025 - val_loss: 6.4714\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "rnn_history = rnn_model.fit(\n",
        "    X_padded, y_encoded,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ9soJjNJkeE",
        "outputId": "c8f3eed5-dc38-4992-9bec-2cef17000783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 55ms/step - accuracy: 0.0385 - loss: 7.1046 - val_accuracy: 0.0460 - val_loss: 6.6788\n",
            "Epoch 2/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 54ms/step - accuracy: 0.0554 - loss: 6.3559 - val_accuracy: 0.0621 - val_loss: 6.5530\n",
            "Epoch 3/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 54ms/step - accuracy: 0.0746 - loss: 6.0966 - val_accuracy: 0.0874 - val_loss: 6.4747\n",
            "Epoch 4/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 54ms/step - accuracy: 0.0951 - loss: 5.8555 - val_accuracy: 0.0951 - val_loss: 6.4527\n",
            "Epoch 5/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 55ms/step - accuracy: 0.1068 - loss: 5.6824 - val_accuracy: 0.0994 - val_loss: 6.4403\n",
            "Epoch 6/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 54ms/step - accuracy: 0.1179 - loss: 5.4850 - val_accuracy: 0.1026 - val_loss: 6.4469\n",
            "Epoch 7/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 54ms/step - accuracy: 0.1278 - loss: 5.3328 - val_accuracy: 0.1071 - val_loss: 6.4725\n",
            "Epoch 8/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 54ms/step - accuracy: 0.1333 - loss: 5.1791 - val_accuracy: 0.1083 - val_loss: 6.4917\n",
            "Epoch 9/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 54ms/step - accuracy: 0.1387 - loss: 5.0380 - val_accuracy: 0.1108 - val_loss: 6.5380\n",
            "Epoch 10/100\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 56ms/step - accuracy: 0.1501 - loss: 4.8855 - val_accuracy: 0.1121 - val_loss: 6.5888\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Stop if validation loss does not improve for 5 epochs\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_padded, y_encoded,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzUZIiloJkeF"
      },
      "source": [
        "## 9. Save models and artifacts\n",
        "\n",
        "Save the trained models **and** the tokenizer, encoder, and max_length so you can load them later for prediction without retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esx_3oN4JkeF",
        "outputId": "ac9ecc8b-cea0-409f-c74f-cedc9c51b44d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save Keras models\n",
        "lstm_model.save('/content/drive/MyDrive/lstm_model.h5')\n",
        "rnn_model.save('/content/drive/MyDrive/rnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml8XwvWiJkeF",
        "outputId": "4835125f-265f-4c97-9885-d7e7fcec3b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: lstm_model.h5, rnn_model.h5, tokenizer.pkl, encoder.pkl, config.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save tokenizer - we need it later to turn new text into number sequences\n",
        "f = open('/content/drive/MyDrive/tokenizer.pkl', 'wb')\n",
        "pickle.dump(tokenizer, f)\n",
        "f.close()\n",
        "\n",
        "# Save encoder - the sklearn one-hot encoder (in case we need it again)\n",
        "f = open('/content/drive/MyDrive/encoder.pkl', 'wb')\n",
        "pickle.dump(encoder, f)\n",
        "f.close()\n",
        "\n",
        "# Build index_to_word: for each word and its number, store number -> word\n",
        "index_to_word = {}\n",
        "for word, index in word_index.items():\n",
        "    index_to_word[index] = word\n",
        "\n",
        "# Save max_length, vocab_size, and index_to_word together in config\n",
        "config = {}\n",
        "config['max_length'] = max_length\n",
        "config['vocab_size'] = vocab_size\n",
        "config['index_to_word'] = index_to_word\n",
        "f = open('/content/drive/MyDrive/config.pkl', 'wb')\n",
        "pickle.dump(config, f)\n",
        "f.close()\n",
        "\n",
        "print('Saved: lstm_model.h5, rnn_model.h5, tokenizer.pkl, encoder.pkl, config.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RBL89GZJkeF"
      },
      "source": [
        "## 10. Prediction: next-word and sentence generation\n",
        "\n",
        "We need the reverse mapping (index → word) and the predictor function. When loading in a new session, load the model plus tokenizer, config (max_length, index_to_word) from the saved files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TpF0x6dJkeF",
        "outputId": "1d38541f-af1a-4b92-df57-5175b8616acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example indices to words: [(1, 'the'), (2, 'you'), (3, 'to'), (4, 'and'), (5, 'a')]\n"
          ]
        }
      ],
      "source": [
        "# Build index_to_word: given an index (number), get the word\n",
        "# When we load from file we get this from config.pkl; here we build it from word_index\n",
        "index_to_word = {}\n",
        "for word, index in word_index.items():\n",
        "    index_to_word[index] = word\n",
        "print('Example indices to words:', list(index_to_word.items())[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WRaTCUnuJkeF"
      },
      "outputs": [],
      "source": [
        "def predictor(model, tokenizer, text, max_len):\n",
        "    # Make text lowercase and turn it into a sequence of numbers\n",
        "    text = text.lower()\n",
        "    seq = tokenizer.texts_to_sequences([text])[0]\n",
        "    seq_padded = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
        "    # Model gives probabilities for each word; we take the one with highest probability\n",
        "    pred = model.predict(seq_padded, verbose=0)\n",
        "    pred_index = np.argmax(pred[0])  # this is 0-based; tokenizer uses 1-based\n",
        "    word_index_to_use = pred_index + 1\n",
        "    if word_index_to_use in index_to_word:\n",
        "        return index_to_word[word_index_to_use]\n",
        "    return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ1lBoYYJkeG",
        "outputId": "bce9c4d2-0af4-4962-f264-6da56fbf9e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: life is\n",
            "Next word: a\n"
          ]
        }
      ],
      "source": [
        "# Test: predict next word for \"life is\"\n",
        "seed_text = \"life is\"\n",
        "next_word = predictor(lstm_model, tokenizer, seed_text, max_length)\n",
        "print('Seed:', seed_text)\n",
        "print('Next word:', next_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nn5U1PfwJkeG"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, tokenizer, seed_text, max_len, num_words):\n",
        "    # Add one word at a time, num_words times\n",
        "    for i in range(num_words):\n",
        "        next_word = predictor(model, tokenizer, seed_text, max_len)\n",
        "        if next_word == '':\n",
        "            break\n",
        "        seed_text = seed_text + ' ' + next_word\n",
        "    return seed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my7GmiwaJkeG",
        "outputId": "6a281b69-16b5-423f-9832-54465a336e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: life is a world is the world is the world is the\n"
          ]
        }
      ],
      "source": [
        "# Generate 10 more words from \"life is\"\n",
        "seed_text = \"life is\"\n",
        "generated = generate_text(lstm_model, tokenizer, seed_text, max_length, 10)\n",
        "print('Generated:', generated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
